{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "im1=cv2.imread(\"12a.jpg\")\n",
    "im2=cv2.imread(\"12b.jpg\")\n",
    "\n",
    "im1=cv2.pyrDown(im1)\n",
    "im2=cv2.pyrDown(im2)\n",
    "\n",
    "#detecting points of interest and computing descriptors\n",
    "detector = cv2.xfeatures2d.SIFT_create()\n",
    "#detector = cv2.AKAZE_create() #Alternative if xfeature2d not available\n",
    "\n",
    "p1, d1 = detector.detectAndCompute(im1, None)\n",
    "p2, d2 = detector.detectAndCompute(im2, None)\n",
    "\n",
    "#matching points of interest\n",
    "matcher = cv2.BFMatcher(cv2.NORM_L2)\n",
    "raw_matches = matcher.knnMatch(d1, trainDescriptors = d2, k = 2) \n",
    "\n",
    "#filtering the matches\n",
    "mp1, mp2 = [], [] \n",
    "ratio=0.65\n",
    "for m in raw_matches:\n",
    "    if len(m) == 2 and m[0].distance < m[1].distance * ratio:\n",
    "        mp1.append( p1[m[0].queryIdx] )\n",
    "        mp2.append( p2[m[0].trainIdx] )\n",
    "pt1 = np.float32([p.pt for p in mp1])\n",
    "pt2 = np.float32([p.pt for p in mp2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_rigid = cv2.estimateRigidTransform(pt1, pt2, False)\n",
    "h=np.vstack([tr_rigid,[0,0,1]]) \n",
    "#h=cv2.findHomography(p1, p2, cv2.RANSAC, 5.0) #general transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-906fadf03c05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0moutput_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarped_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0moutput_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mint_corners\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcornersTrans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcornersTrans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcornersTrans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mallmins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcornersTrans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mallmins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcornersTrans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcornersTrans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "corners = np.array([[[0,0]],[[0,im1.shape[0]]],[[im1.shape[1],0]],[[im1.shape[1],im1.shape[0]]]], dtype=np.float32)\n",
    "cornersTrans = cv2.perspectiveTransform(corners,h)\n",
    "\n",
    "mins = np.amin(cornersTrans, axis=0).astype(np.int)\n",
    "maxs = np.amax(cornersTrans, axis=0).astype(np.int)\n",
    "\n",
    "cornersAll=np.concatenate((cornersTrans,corners))\n",
    "\n",
    "allmins = np.amin(cornersAll, axis=0).astype(np.int)\n",
    "allmaxs = np.amax(cornersAll, axis=0).astype(np.int)\n",
    "\n",
    "tH=np.dot([[1, 0, -1 * allmins[0][0]], [0, 1, -1 * allmins[0][1]], [0, 0, 1]],h)\n",
    "\n",
    "warped_image = cv2.warpPerspective(im1, tH, (allmaxs[0][0] - allmins[0][0], allmaxs[0][1] - allmins[0][1])) \n",
    "\n",
    "point = np.array(-allmins[0][0],  -allmins[0][1]).astype(np.int)\n",
    "\n",
    "output_image=np.zeros_like(warped_image)\n",
    "output_image[point[1]:point[1] + im2.shape[0],point[0]:point[0] + im2.shape[1]] = im2\n",
    "\n",
    "int_corners=[[max(cornersTrans[0][0,0],cornersTrans[1][0,0]),max(0,cornersTrans[0][0,1]-allmins[0][1],cornersTrans[2][0,1]-allmins[0][1])], [im1.shape[1],max(cornersTrans[1][0,1],cornersTrans[3][0,1])]]            \n",
    "\n",
    "int1=output_image[int_corners[0][1]:int_corners[1][1],int_corners[0][0]:int_corners[1][0]]\n",
    "int2=warped_image[int_corners[0][1]:int_corners[1][1], int_corners[0][0]:int_corners[1][0]]\n",
    "\n",
    "fx=np.arange(int1.shape[1])/(1.*int1.shape[1])\n",
    "f1=int1*(1-fx[:,np.newaxis])\n",
    "f2=int2*fx[:,np.newaxis]\n",
    "res=(f1+f2)\n",
    "\n",
    "output_image+=warped_image\n",
    "output_image[int_corners[0][1]:int_corners[1][1],int_corners[0][0]:int_corners[1][0]]=res.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
